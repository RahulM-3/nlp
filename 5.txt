# Install spaCy
!pip install -U spacy

# Download English model
!python -m spacy download en_core_web_sm

import spacy
from itertools import islice

# Load English model
nlp = spacy.load("en_core_web_sm")

# Sample text
text = "Natural Language Processing enables computers to understand human language."

# Tokenize using spaCy
doc = nlp(text)
tokens = [token.text for token in doc if not token.is_punct and not token.is_space]

print("ðŸ”¹ Tokens:", tokens)

# User-defined n-gram generator
def generate_ngrams(tokens, n):
    return list(zip(*(islice(tokens, i, None) for i in range(n))))

# Unigrams
print("\nðŸ”¸ Unigrams:")
print(generate_ngrams(tokens, 1))

# Bigrams
print("\nðŸ”¸ Bigrams:")
print(generate_ngrams(tokens, 2))


# Trigrams
print("\nðŸ”¸ Trigrams:")
print(generate_ngrams(tokens, 3))

# N-grams (e.g., 4-grams)
n = 4
print(f"\nðŸ”¸ {n}-grams:")
print(generate_ngrams(tokens, n))
