from sklearn.datasets import fetch_20newsgroups
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.linear_model import LogisticRegression
from sklearn.pipeline import Pipeline
from sklearn.metrics import accuracy_score, classification_report

# Load dataset (keep headers/footers)
train_data = fetch_20newsgroups(subset='train')
test_data = fetch_20newsgroups(subset='test')

X_train, y_train = train_data.data, train_data.target
X_test, y_test = test_data.data, test_data.target

# TF-IDF setup (word-level, tuned for accuracy)
tfidf = TfidfVectorizer(
    stop_words='english',
    max_df=0.6,
    min_df=4,
    ngram_range=(1, 2),
    sublinear_tf=True,
    max_features=50000
)

# ====== Naive Bayes ======
nb_pipeline = Pipeline([
    ('tfidf', tfidf),
    ('clf', MultinomialNB(alpha=0.05))
])
nb_pipeline.fit(X_train, y_train)
nb_pred = nb_pipeline.predict(X_test)



print("\nðŸ”¸ Naive Bayes Results ðŸ”¸")
print("Accuracy:", round(accuracy_score(y_test, nb_pred) * 100, 2), "%")
print(classification_report(y_test, nb_pred, target_names=test_data.target_names))

# ====== Logistic Regression ======
svm_pipeline = Pipeline([
    ('tfidf', tfidf),
    ('clf', LogisticRegression(C=1.5, solver='lbfgs', max_iter=2000))
])
svm_pipeline.fit(X_train, y_train)
svm_pred = svm_pipeline.predict(X_test)

print("\nðŸ”¸ Logistic Regression (SVM-like) Results ðŸ”¸")
print("Accuracy:", round(accuracy_score(y_test, svm_pred) * 100, 2), "%")
print(classification_report(y_test, svm_pred, target_names=test_data.target_names))
